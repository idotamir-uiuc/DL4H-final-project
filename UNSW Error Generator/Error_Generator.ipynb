{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce datasets for Scheme B\n",
    "\n",
    "Paper: \"Statistical supervised meta-ensemble algorithm for data linkage\"\n",
    "\n",
    "Kha Vo, Jitendra Jonnagaddala, Siaw-Teng Liaw\n",
    "\n",
    "February 2019\n",
    "\n",
    "Jounal of Biomedical Informatics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = 'ePBRN_F_original' # change between 'ePBRN_D_original' or 'ePBRN_F_original'\n",
    "outputfile = 'ePBRN_F_dup' # change between 'ePBRN_D_dup' or 'ePBRN_F_dup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from numpy.random import choice\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the percentage of  [2, 3, 4] shared records in one linkage:\n",
    "count_shared = [1.68+21.0659, 1.9986 + 0.0471, 0.05]\n",
    "\n",
    "# Assigning the weights for each type of error:\n",
    "\n",
    "abr = 1 # abbreviation on surname: Michael -> M\n",
    "jwd1 = 1 # join with dash: John Peter -> John-Peter, join surname and given name into surname\n",
    "jwd2 = 1 # join with dash: John Peter -> John-Peter, join surname and given name into given name\n",
    "jwb1 = 1 # join with blank: \n",
    "jwb2 = 1 # join with blank: \n",
    "drf = 1 # drop all tokens in any field\n",
    "dlc1 = 1 # drop last character in surname: Peter -> Pete\n",
    "dlc2 = 1 # drop last character in given name\n",
    "swn = 1 # swap surname and given name: John Peter -> Peter John\n",
    "#swc1 = 1 # swap character in surname: Peter -> Petre\n",
    "#swc2 = 1 # swap character in given name: Peter -> Petre\n",
    "swd = 1 # swap day and month fields: 12/04 -> 04/12\n",
    "rsd = 1 # reset day and month: 12/04/1991 -> 01/01/1991\n",
    "chy = 1 # change year of birth by a margin of (+/-)5 \n",
    "#drz1 = 1 # drop leading zeros from day of birth: 02/04 -> 2/04\n",
    "#drz2 = 1 # drop leading zeros from month of birth: 02/04 -> 02/4\n",
    "chz = 1 # change any number of digit from zip code\n",
    "mar = 1 # change the whole token of surname: Mary Ward -> Mary Winston\n",
    "twi = 1 # duplicate all fields except given name: Micheal Williams -> Leo Williams\n",
    "add = 1 # change the whole 3 fields of address by randomly replacing each field by any other row\n",
    "\n",
    "all_error_types = ['abr','jwd1','jwd2','jwb1','jwb2' ,'drf','dlc1','dlc2','swn',\n",
    "                   'rsd','chy','chz','mar','twi','add']\n",
    "all_error_weights = [abr, jwd1, jwd2, jwb1, jwb2, drf, dlc1, dlc2, swn, rsd, chy, chz, mar, twi, add]\n",
    "all_error_weights = all_error_weights/sum(np.asarray(all_error_weights))\n",
    "\n",
    "def process_record(rc):\n",
    "    no_error = np.random.poisson(1, 1)\n",
    "    errortypes = choice(all_error_types, no_error, p=all_error_weights)\n",
    "    for errortype in errortypes:\n",
    "        if errortype == 'abr':\n",
    "            if len(rc[\"surname\"])>0:\n",
    "                #rc[\"surname\"] = rc[\"surname\"][0]\n",
    "                rc.at[\"surname\"] = rc[\"surname\"][0]\n",
    "        if errortype == 'jwd1':\n",
    "            rc.at[\"surname\"] = rc[\"surname\"]+'-' +rc[\"given_name\"]\n",
    "            rc.at[\"given_name\"] = ''\n",
    "        if errortype == 'jwd2':\n",
    "            rc.at[\"given_name\"] = rc[\"surname\"]+'-' +rc[\"given_name\"]\n",
    "            rc.at[\"surname\"] = ''\n",
    "        if errortype == 'jwb1':\n",
    "            rc.at[\"surname\"] = rc[\"surname\"]+' ' +rc[\"given_name\"]\n",
    "            rc.at[\"given_name\"] = ''\n",
    "        if errortype == 'jwb2':\n",
    "            rc.at[\"given_name\"] = rc[\"surname\"]+' ' +rc[\"given_name\"]\n",
    "            rc.at[\"surname\"] = ''\n",
    "        if errortype == 'drf':    \n",
    "            selected_field = random.choice(all_fields)\n",
    "            rc.at[selected_field] = ''\n",
    "        if errortype == 'dlc1':\n",
    "            if len(rc[\"surname\"])>0:\n",
    "                rc.at[\"surname\"] = rc['surname'][0:-1]\n",
    "        if errortype == 'dlc2':\n",
    "            if len(rc[\"given_name\"])>0:\n",
    "                rc.at[\"given_name\"] = rc['given_name'][0:-1]\n",
    "        if errortype == 'swn':\n",
    "            temp = rc['given_name']\n",
    "            rc.at[\"given_name\"] = rc['surname']\n",
    "            rc.at[\"surname\"] = temp\n",
    "        if errortype == 'swd': \n",
    "            temp = rc['day']\n",
    "            rc.at['day'] = rc['month']\n",
    "            rc.at['month'] = temp\n",
    "        if errortype == 'rsd':\n",
    "            rc.at['day'] = '01'\n",
    "            rc.at['month'] = '01'\n",
    "        if errortype == 'chy': \n",
    "            if rc.at['year'] != 'NaT' and rc['year'] != '':\n",
    "                margin = random.choice(range(-5,5))\n",
    "                rc.at['year'] = str( int(rc['year']) + margin)\n",
    "        if errortype == 'chz':\n",
    "            if len(str(rc['postcode']))== 4:\n",
    "                selected_digit = random.choice(range(4))\n",
    "                code = list(str(rc['postcode']))\n",
    "                code[selected_digit] = str( random.choice(range(9)))\n",
    "                rc.at['postcode'] = int(''.join(code))\n",
    "        if errortype == 'mar':\n",
    "            rc.at[\"surname\"] = df.iloc[random.choice(range(len(df)))]['surname']\n",
    "        if errortype == 'twi':\n",
    "            rc.at[\"given_name\"] = df.iloc[random.choice(range(len(df)))]['given_name']\n",
    "        if errortype == 'add':\n",
    "            rc.at['address_1'] = df.iloc[random.choice(range(len(df)))]['address_1']\n",
    "            rc.at['address_2'] = df.iloc[random.choice(range(len(df)))]['address_2']\n",
    "            rc.at['street_number'] = random.choice(range(500))\n",
    "    return rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset length: 11100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>match_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>jenna</td>\n",
       "      <td>kilpin</td>\n",
       "      <td>179</td>\n",
       "      <td>mcfarlan place</td>\n",
       "      <td></td>\n",
       "      <td>hillarys</td>\n",
       "      <td>2768</td>\n",
       "      <td>vic</td>\n",
       "      <td>26</td>\n",
       "      <td>02</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bianca</td>\n",
       "      <td>randazzo</td>\n",
       "      <td>37</td>\n",
       "      <td>lindrum crescent</td>\n",
       "      <td>sunshine</td>\n",
       "      <td>forster</td>\n",
       "      <td>2281</td>\n",
       "      <td>wa</td>\n",
       "      <td>07</td>\n",
       "      <td>04</td>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>james</td>\n",
       "      <td>borlase</td>\n",
       "      <td>75</td>\n",
       "      <td></td>\n",
       "      <td>rocklea</td>\n",
       "      <td>casula</td>\n",
       "      <td>2460</td>\n",
       "      <td>qld</td>\n",
       "      <td>03</td>\n",
       "      <td>09</td>\n",
       "      <td>1913</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>nicholas</td>\n",
       "      <td>beeton</td>\n",
       "      <td>20</td>\n",
       "      <td>mugga way</td>\n",
       "      <td></td>\n",
       "      <td>hawthorn</td>\n",
       "      <td>2480</td>\n",
       "      <td>vic</td>\n",
       "      <td>22</td>\n",
       "      <td>06</td>\n",
       "      <td>1999</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>megan</td>\n",
       "      <td>footner</td>\n",
       "      <td>4</td>\n",
       "      <td>jewell close</td>\n",
       "      <td></td>\n",
       "      <td>taylors lakes</td>\n",
       "      <td>3129</td>\n",
       "      <td>tas</td>\n",
       "      <td>22</td>\n",
       "      <td>09</td>\n",
       "      <td>1912</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rec_id given_name   surname  street_number         address_1 address_2  \\\n",
       "0      0      jenna    kilpin            179    mcfarlan place             \n",
       "1      1     bianca  randazzo             37  lindrum crescent  sunshine   \n",
       "2      2      james   borlase             75                     rocklea   \n",
       "3      3   nicholas    beeton             20         mugga way             \n",
       "4      4      megan   footner              4      jewell close             \n",
       "\n",
       "          suburb  postcode state day month  year  match_id  \n",
       "0       hillarys      2768   vic  26    02  1950         0  \n",
       "1        forster      2281    wa  07    04  1988         1  \n",
       "2         casula      2460   qld  03    09  1913         2  \n",
       "3       hawthorn      2480   vic  22    06  1999         3  \n",
       "4  taylors lakes      3129   tas  22    09  1912         4  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess\n",
    "df = pd.read_csv(\n",
    "    r\"ePBRN_Datasets/\"+inputfile+\".csv\", \n",
    "    parse_dates=[\"date_of_birth\"])\n",
    "\n",
    "df[\"rec_id\"] = range(len(df))\n",
    "df['rec_id'] = df['rec_id'].astype(str)\n",
    "df['day'] = df['date_of_birth'].dt.strftime('%d')\n",
    "df['month'] = df['date_of_birth'].dt.strftime('%m')\n",
    "df['year'] = df['date_of_birth'].dt.strftime('%Y')\n",
    "df['postcode'] =   df['postcode'].fillna('0000')\n",
    "df['postcode'] = df['postcode'].astype(int)\n",
    "df['street_number'] =   df['street_number'].fillna('0')\n",
    "df['street_number'] = df['street_number'].astype(int)\n",
    "df = df.drop([\"age\", \"phone_number\", \"soc_sec_id\", \"blocking_number\", \"date_of_birth\"], axis=1)\n",
    "for col in [\"surname\", \"given_name\", \"address_1\", \"address_2\", \"day\", \"month\"]:\n",
    "    df[col] = df[col].fillna('')\n",
    "    df[col] = df[col].astype(str)\n",
    "df[\"match_id\"] = range(len(df))\n",
    "all_fields = df.columns.values.tolist()\n",
    "all_fields.remove('rec_id')\n",
    "\n",
    "print(\"Original dataset length:\",len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process ePBRN_F_original , total records: 11100 ...\n",
      "Double links: 2524 . Triple links: 227 . Quad links: 0\n",
      "Total records after generated: 14078\n",
      "Matched pairs: 3205\n"
     ]
    }
   ],
   "source": [
    "# Generate random indices for linkages\n",
    "leng = len(df)\n",
    "print(\"Process\", inputfile, \", total records:\", leng, \"...\")\n",
    "no_double_linked = int(leng*count_shared[0]/100)\n",
    "no_triple_linked = int(leng*count_shared[1]/100)\n",
    "no_quad_linked = int(leng*count_shared[2]/100)\n",
    "list_double_linked = random.sample(range(leng),k=no_double_linked)\n",
    "remain = [item for item in range(leng) if item not in list_double_linked]\n",
    "list_triple_linked = random.sample(remain,k=no_triple_linked)\n",
    "remain = [item for item in remain if item not in list_triple_linked]\n",
    "list_quad_linked = random.sample(remain,k=no_quad_linked)\n",
    "print(\"Double links:\", no_double_linked,\". Triple links:\",no_triple_linked,\". Quad links:\",no_quad_linked)\n",
    "print(\"Total records after generated:\", leng + no_double_linked + no_triple_linked*2 + no_quad_linked*3)\n",
    "print(\"Matched pairs:\", no_double_linked + no_triple_linked*3 + no_quad_linked*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ePBRN_Datasets/ePBRN_F_dup.csv\n"
     ]
    }
   ],
   "source": [
    "# Main steps\n",
    "df1 = df\n",
    "j = 0\n",
    "for list_linked in [list_double_linked, list_triple_linked, list_quad_linked]:\n",
    "    j = j + 1\n",
    "    for i in list_linked:\n",
    "        for k in range(j):\n",
    "            record_to_process = df.iloc[i]\n",
    "            processed_rc = process_record(record_to_process)\n",
    "            processed_rc.at[\"rec_id\"] = processed_rc[\"rec_id\"] + \"-dup-\" + str(k)\n",
    "            df1 = df1.append(processed_rc)\n",
    "\n",
    "# Save to disk    \n",
    "outputpath = r\"ePBRN_Datasets/\"+ outputfile + \".csv\"\n",
    "df1.to_csv(outputpath, index=False)\n",
    "print(\"Saved to\", outputpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
