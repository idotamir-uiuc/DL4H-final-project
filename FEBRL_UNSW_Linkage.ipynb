{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce results of Scheme A\n",
    "\n",
    "Paper: \"Statistical supervised meta-ensemble algorithm for data linkage\"\n",
    "\n",
    "Kha Vo, Jitendra Jonnagaddala, Siaw-Teng Liaw\n",
    "\n",
    "February 2019\n",
    "\n",
    "Jounal of Biomedical Informatics\n",
    "\n",
    "Paper: \"Statistical supervised meta-ensemble algorithm for data linkage\"\n",
    "\n",
    "Kha Vo, Jitendra Jonnagaddala, Siaw-Teng Liaw\n",
    "\n",
    "February 2019\n",
    "\n",
    "Jounal of Biomedical Informatics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import recordlinkage as rl, pandas as pd, numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from recordlinkage.preprocessing import phonetic\n",
    "from numpy.random import choice\n",
    "import collections, numpy\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_true_links(df): \n",
    "    # although the match_id column is included in the original df to imply the true links,\n",
    "    # this function will create the true_link object identical to the true_links properties\n",
    "    # of recordlinkage toolkit, in order to exploit \"Compare.compute()\" from that toolkit\n",
    "    # in extract_function() for extracting features quicker.\n",
    "    # This process should be deprecated in the future release of the UNSW toolkit.\n",
    "    df[\"rec_id\"] = df.index.values.tolist()\n",
    "    indices_1 = []\n",
    "    indices_2 = []\n",
    "    processed = 0\n",
    "    for match_id in df[\"match_id\"].unique():\n",
    "        if match_id != -1:    \n",
    "            processed = processed + 1\n",
    "            # print(\"In routine generate_true_links(), count =\", processed)\n",
    "            # clear_output(wait=True)\n",
    "            linkages = df.loc[df['match_id'] == match_id]\n",
    "            for j in range(len(linkages)-1):\n",
    "                for k in range(j+1, len(linkages)):\n",
    "                    indices_1 = indices_1 + [linkages.iloc[j][\"rec_id\"]]\n",
    "                    indices_2 = indices_2 + [linkages.iloc[k][\"rec_id\"]]    \n",
    "    links = pd.MultiIndex.from_arrays([indices_1,indices_2])\n",
    "    return links\n",
    "\n",
    "def generate_false_links(df, size):\n",
    "    # A counterpart of generate_true_links(), with the purpose to generate random false pairs\n",
    "    # for training. The number of false pairs in specified as \"size\".\n",
    "    df[\"rec_id\"] = df.index.values.tolist()\n",
    "    indices_1 = []\n",
    "    indices_2 = []\n",
    "    unique_match_id = df[\"match_id\"].unique()\n",
    "    for j in range(size):\n",
    "            false_pair_ids = choice(unique_match_id, 2)\n",
    "            candidate_1_cluster = df.loc[df['match_id'] == false_pair_ids[0]]\n",
    "            candidate_1 = candidate_1_cluster.iloc[choice(range(len(candidate_1_cluster)))]\n",
    "            candidate_2_cluster = df.loc[df['match_id'] == false_pair_ids[1]]\n",
    "            candidate_2 = candidate_2_cluster.iloc[choice(range(len(candidate_2_cluster)))]    \n",
    "            indices_1 = indices_1 + [candidate_1[\"rec_id\"]]\n",
    "            indices_2 = indices_2 + [candidate_2[\"rec_id\"]]  \n",
    "    links = pd.MultiIndex.from_arrays([indices_1,indices_2])\n",
    "    return links\n",
    "\n",
    "def swap_fields_flag(f11, f12, f21, f22):\n",
    "    return int((f11 == f22) and (f12 == f21))\n",
    "\n",
    "def extract_features(df, links):\n",
    "    c = rl.Compare()\n",
    "    c.string('given_name', 'given_name', method='jarowinkler', label='y_name')\n",
    "    c.string('given_name_soundex', 'given_name_soundex', method='jarowinkler', label='y_name_soundex')\n",
    "    c.string('given_name_nysiis', 'given_name_nysiis', method='jarowinkler', label='y_name_nysiis')\n",
    "    c.string('surname', 'surname', method='jarowinkler', label='y_surname')\n",
    "    c.string('surname_soundex', 'surname_soundex', method='jarowinkler', label='y_surname_soundex')\n",
    "    c.string('surname_nysiis', 'surname_nysiis', method='jarowinkler', label='y_surname_nysiis')\n",
    "    c.exact('street_number', 'street_number', label='y_street_number')\n",
    "    c.string('address_1', 'address_1', method='levenshtein', threshold=0.7, label='y_address1')\n",
    "    c.string('address_2', 'address_2', method='levenshtein', threshold=0.7, label='y_address2')\n",
    "    c.exact('postcode', 'postcode', label='y_postcode')\n",
    "    c.exact('day', 'day', label='y_day')\n",
    "    c.exact('month', 'month', label='y_month')\n",
    "    c.exact('year', 'year', label='y_year')\n",
    "        \n",
    "    # Build features\n",
    "    feature_vectors = c.compute(links, df, df)\n",
    "    return feature_vectors\n",
    "\n",
    "def generate_train_X_y(df):\n",
    "    # This routine is to generate the feature vector X and the corresponding labels y\n",
    "    # with exactly equal number of samples for both classes to train the classifier.\n",
    "    pos = extract_features(df, train_true_links)\n",
    "    train_false_links = generate_false_links(df, len(train_true_links))    \n",
    "    neg = extract_features(df, train_false_links)\n",
    "    X = pos.values.tolist() + neg.values.tolist()\n",
    "    y = [1]*len(pos)+[0]*len(neg)\n",
    "    X, y = shuffle(X, y, random_state=0)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "def train_model(modeltype, modelparam, train_vectors, train_labels, modeltype_2):\n",
    "    if modeltype == 'svm': # Support Vector Machine\n",
    "        model = svm.SVC(C = modelparam, kernel = modeltype_2)\n",
    "        model.fit(train_vectors, train_labels) \n",
    "    elif modeltype == 'lg': # Logistic Regression\n",
    "        model = LogisticRegression(C=modelparam, penalty = modeltype_2,class_weight=None, dual=False, fit_intercept=True, \n",
    "                                   intercept_scaling=1, max_iter=5000, multi_class='ovr', \n",
    "                                   n_jobs=1, random_state=None)\n",
    "        model.fit(train_vectors, train_labels)\n",
    "    elif modeltype == 'nb': # Naive Bayes\n",
    "        model = GaussianNB()\n",
    "        model.fit(train_vectors, train_labels)\n",
    "    elif modeltype == 'nn': # Neural Network\n",
    "        model = MLPClassifier(solver='lbfgs', alpha=modelparam, hidden_layer_sizes=(256, ), \n",
    "                              activation = modeltype_2,random_state=None, batch_size='auto', \n",
    "                              learning_rate='constant',  learning_rate_init=0.001, \n",
    "                              power_t=0.5, max_iter=10000, shuffle=True, \n",
    "                              tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                              nesterovs_momentum=True, early_stopping=False, \n",
    "                              validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "        model.fit(train_vectors, train_labels)\n",
    "    return model\n",
    "\n",
    "def classify(model, test_vectors):\n",
    "    result = model.predict(test_vectors)\n",
    "    return result\n",
    "\n",
    "    \n",
    "def evaluation(test_labels, result):\n",
    "    true_pos = np.logical_and(test_labels, result)\n",
    "    count_true_pos = np.sum(true_pos)\n",
    "    true_neg = np.logical_and(np.logical_not(test_labels),np.logical_not(result))\n",
    "    count_true_neg = np.sum(true_neg)\n",
    "    false_pos = np.logical_and(np.logical_not(test_labels), result)\n",
    "    count_false_pos = np.sum(false_pos)\n",
    "    false_neg = np.logical_and(test_labels,np.logical_not(result))\n",
    "    count_false_neg = np.sum(false_neg)\n",
    "    precision = count_true_pos/(count_true_pos+count_false_pos)\n",
    "    sensitivity = count_true_pos/(count_true_pos+count_false_neg) # sensitivity = recall\n",
    "    confusion_matrix = [count_true_pos, count_false_pos, count_false_neg, count_true_neg]\n",
    "    no_links_found = np.count_nonzero(result)\n",
    "    no_false = count_false_pos + count_false_neg\n",
    "    Fscore = 2*precision*sensitivity/(precision+sensitivity)\n",
    "    metrics_result = {'no_false':no_false, 'confusion_matrix':confusion_matrix ,'precision':precision,\n",
    "                     'sensitivity':sensitivity ,'no_links':no_links_found, 'F-score': Fscore}\n",
    "    return metrics_result\n",
    "\n",
    "def blocking_performance(candidates, true_links, df):\n",
    "    count = 0\n",
    "    for candi in candidates:\n",
    "        if df.loc[candi[0]][\"match_id\"]==df.loc[candi[1]][\"match_id\"]:\n",
    "            count = count + 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = 'febrl3_UNSW'\n",
    "testset = 'febrl4_UNSW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import train set...\n",
      "Train set size: 5000 , number of matched pairs:  1165\n",
      "Finished building X_train, y_train\n"
     ]
    }
   ],
   "source": [
    "## TRAIN SET CONSTRUCTION\n",
    "\n",
    "# Import\n",
    "print(\"Import train set...\")\n",
    "df_train = pd.read_csv(trainset+\".csv\", index_col = \"rec_id\")\n",
    "train_true_links = generate_true_links(df_train)\n",
    "print(\"Train set size:\", len(df_train), \", number of matched pairs: \", str(len(train_true_links)))\n",
    "\n",
    "# Preprocess train set\n",
    "df_train['postcode'] = df_train['postcode'].astype(str)\n",
    "df_train['given_name_soundex'] = phonetic(df_train['given_name'], method='soundex')\n",
    "df_train['given_name_nysiis'] = phonetic(df_train['given_name'], method='nysiis')\n",
    "df_train['surname_soundex'] = phonetic(df_train['surname'], method='soundex')\n",
    "df_train['surname_nysiis'] = phonetic(df_train['surname'], method='nysiis')\n",
    "\n",
    "# Final train feature vectors and labels\n",
    "X_train, y_train = generate_train_X_y(df_train)\n",
    "print(\"Finished building X_train, y_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2330, 13)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n"
     ]
    }
   ],
   "source": [
    "# Blocking Criteria: declare non-match of all of the below fields disagree\n",
    "# Import\n",
    "print(\"Import test set...\")\n",
    "df_test = pd.read_csv(testset+\".csv\", index_col = \"rec_id\")\n",
    "test_true_links = generate_true_links(df_test)\n",
    "leng_test_true_links = len(test_true_links)\n",
    "print(\"Test set size:\", len(df_test), \", number of matched pairs: \", str(leng_test_true_links))\n",
    "\n",
    "print(\"BLOCKING PERFORMANCE:\")\n",
    "blocking_fields = [\"given_name\", \"surname\", \"postcode\"]\n",
    "all_candidate_pairs = []\n",
    "for field in blocking_fields:\n",
    "    block_indexer = rl.Index()\n",
    "    block_indexer.block(on=field)\n",
    "#     block_indexer = rl.BlockIndex(on=field)\n",
    "    candidates = block_indexer.index(df_test)\n",
    "    detects = blocking_performance(candidates, test_true_links, df_test)\n",
    "    all_candidate_pairs = candidates.union(all_candidate_pairs)\n",
    "    print(\"Number of pairs of matched \"+ field +\": \"+str(len(candidates)), \", detected \",\n",
    "         detects,'/'+ str(leng_test_true_links) + \" true matched pairs, missed \" + \n",
    "          str(leng_test_true_links-detects) )\n",
    "detects = blocking_performance(all_candidate_pairs, test_true_links, df_test)\n",
    "print(\"Number of pairs of at least 1 field matched: \" + str(len(all_candidate_pairs)), \", detected \",\n",
    "     detects,'/'+ str(leng_test_true_links) + \" true matched pairs, missed \" + \n",
    "          str(leng_test_true_links-detects) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n"
     ]
    }
   ],
   "source": [
    "## TEST SET CONSTRUCTION\n",
    "\n",
    "# Preprocess test set\n",
    "print(\"Processing test set...\")\n",
    "print(\"Preprocess...\")\n",
    "df_test['postcode'] = df_test['postcode'].astype(str)\n",
    "df_test['given_name_soundex'] = phonetic(df_test['given_name'], method='soundex')\n",
    "df_test['given_name_nysiis'] = phonetic(df_test['given_name'], method='nysiis')\n",
    "df_test['surname_soundex'] = phonetic(df_test['surname'], method='soundex')\n",
    "df_test['surname_nysiis'] = phonetic(df_test['surname'], method='nysiis')\n",
    "\n",
    "# Test feature vectors and labels construction\n",
    "print(\"Extract feature vectors...\")\n",
    "df_X_test = extract_features(df_test, all_candidate_pairs)\n",
    "vectors = df_X_test.values.tolist()\n",
    "labels = [0]*len(vectors)\n",
    "feature_index = df_X_test.index\n",
    "for i in range(0, len(feature_index)):\n",
    "    if df_test.loc[feature_index[i][0]][\"match_id\"]==df_test.loc[feature_index[i][1]][\"match_id\"]:\n",
    "        labels[i] = 1\n",
    "X_test, y_test = shuffle(vectors, labels, random_state=0)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "print(\"Count labels of y_test:\",collections.Counter(y_test))\n",
    "print(\"Finished building X_test, y_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(a):\n",
    "    np_a = np.array(a)\n",
    "    i = np.argmax(np_a)\n",
    "    return np_a[i], i\n",
    "\n",
    "def argmin(a):\n",
    "    np_a = np.array(a)\n",
    "    i = np.argmin(np_a)\n",
    "    return np_a[i], i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE LEARNERS CLASSIFICATION PERFORMANCE:\n",
      "Model: lg , Param_1: none , tuning range: [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 5, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No_false: [653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653] \n",
      "\n",
      "Precision: [0.8839398877421691, 0.8839398877421691, 0.8839398877421691, 0.8839398877421691, 0.8839398877421691, 0.8839398877421691, 0.8839398877421691, 0.8839398877421691, 0.8839398877421691, 0.8839398877421691, 0.8839398877421691, 0.8839398877421691, 0.8839398877421691, 0.8839398877421691, 0.8839398877421691, 0.8839398877421691, 0.8839398877421691, 0.8839398877421691, 0.8839398877421691, 0.8839398877421691] \n",
      "\n",
      "Sensitivity: [0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015] \n",
      "\n",
      "F-score: [0.9373140059518096, 0.9373140059518096, 0.9373140059518096, 0.9373140059518096, 0.9373140059518096, 0.9373140059518096, 0.9373140059518096, 0.9373140059518096, 0.9373140059518096, 0.9373140059518096, 0.9373140059518096, 0.9373140059518096, 0.9373140059518096, 0.9373140059518096, 0.9373140059518096, 0.9373140059518096, 0.9373140059518096, 0.9373140059518096, 0.9373140059518096, 0.9373140059518096] \n",
      "\n",
      "MIN No_false: (653, 0) \n",
      "\n",
      "MAX Precision: (0.8839398877421691, 0) \n",
      "\n",
      "MAX Sensitivity: (0.9975480179812015, 0) \n",
      "\n",
      "MAX F-score: (0.9373140059518096, 0) \n",
      "\n",
      "\n",
      "Model: lg , Param_1: l2 , tuning range: [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 5, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000]\n",
      "No_false: [405, 405, 395, 379, 372, 374, 378, 402, 456, 472, 487, 500, 563, 608, 639, 649, 651, 651, 651, 651] \n",
      "\n",
      "Precision: [0.9332175255742134, 0.9325496242050492, 0.9323467230443975, 0.933384526780572, 0.9334739263803681, 0.9319571865443425, 0.9305873379099924, 0.9260242792109257, 0.916478978978979, 0.9137350299401198, 0.9111774584810599, 0.9089724497393894, 0.8985827351371249, 0.891201168309602, 0.8861862406970412, 0.88458053995289, 0.884260097808368, 0.884260097808368, 0.884260097808368, 0.884260097808368] \n",
      "\n",
      "Sensitivity: [0.9879444217409072, 0.9887617490805067, 0.9912137310993052, 0.9934613812832039, 0.994891704127503, 0.9963220269718022, 0.9971393543114018, 0.9975480179812015, 0.9977523498161014, 0.9977523498161014, 0.9977523498161014, 0.9977523498161014, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015, 0.9975480179812015] \n",
      "\n",
      "F-score: [0.9598014888337468, 0.9598333829217495, 0.9608794691492522, 0.9624863901811344, 0.9632047477744807, 0.9630653762591348, 0.9627145393568751, 0.9604564233720244, 0.9553903345724908, 0.9538972455557726, 0.9525017068175168, 0.9512955386713423, 0.9454827152125496, 0.9413806401851138, 0.9385754109391522, 0.9376740612695669, 0.9374939990398464, 0.9374939990398464, 0.9374939990398464, 0.9374939990398464] \n",
      "\n",
      "MIN No_false: (372, 4) \n",
      "\n",
      "MAX Precision: (0.9334739263803681, 4) \n",
      "\n",
      "MAX Sensitivity: (0.9977523498161014, 8) \n",
      "\n",
      "MAX F-score: (0.9632047477744807, 4) \n",
      "\n",
      "\n",
      "Model: nn , Param_1: relu , tuning range: [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 5, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8r/gq_z1dy90bjc511vv0fncmww0000gn/T/ipykernel_42139/1762433943.py:115: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = count_true_pos/(count_true_pos+count_false_pos)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No_false: [17315, 6857, 7372, 12223, 10095, 8606, 7189, 6465, 4731, 2423, 694, 527, 416, 379, 374, 380, 405, 413, 4894, 367179] \n",
      "\n",
      "Precision: [0.22020993827994775, 0.41640405416915083, 0.398923152227117, 0.28581448360512013, 0.3264134570455911, 0.362436999703528, 0.4049689440993789, 0.43081123932000354, 0.5084728142218525, 0.6690381721165686, 0.8770197486535009, 0.904426745693647, 0.9235716988270904, 0.9310674050028642, 0.9324531190202832, 0.9332053742802303, 0.9325496242050492, 0.9331142470520007, nan, 0.013153332813722038] \n",
      "\n",
      "Sensitivity: [0.9987740089906008, 0.9989783408255006, 0.9991826726604005, 0.9991826726604005, 0.9991826726604005, 0.9991826726604005, 0.9991826726604005, 0.9993870044953004, 0.9993870044953004, 0.9991826726604005, 0.9981610134859011, 0.9977523498161014, 0.9975480179812015, 0.9963220269718022, 0.9957090314671025, 0.9934613812832039, 0.9887617490805067, 0.9863097670617083, 0.0, 1.0] \n",
      "\n",
      "F-score: [0.3608578494703038, 0.5877968139464984, 0.570195895522388, 0.44448484297595786, 0.49207547169811316, 0.5319264657891875, 0.5763450998880311, 0.6020803840709055, 0.6740163990904705, 0.8014422682946816, 0.9336773700305809, 0.9488001554454484, 0.9591355599214146, 0.9625900700819267, 0.9630434782608697, 0.9623911322248615, 0.9598333829217495, 0.9589748683818416, nan, 0.0259651375319325] \n",
      "\n",
      "MIN No_false: (374, 14) \n",
      "\n",
      "MAX Precision: (nan, 18) \n",
      "\n",
      "MAX Sensitivity: (1.0, 19) \n",
      "\n",
      "MAX F-score: (nan, 18) \n",
      "\n",
      "\n",
      "Model: nn , Param_1: logistic , tuning range: [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 5, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000]\n",
      "No_false: [17633, 19661, 15927, 6357, 8342, 5126, 3029, 774, 639, 557, 424, 394, 375, 377, 398, 411, 367179, 367179, 367179, 367179] \n",
      "\n",
      "Precision: [0.21720019535585847, 0.19925868600057023, 0.23500024018830765, 0.43493729431646355, 0.36967039612942243, 0.48841390331602075, 0.6178142766898295, 0.8646017699115044, 0.885766092475068, 0.8989880404783809, 0.9221760483566301, 0.927594070695553, 0.9317790942098223, 0.9334100940318557, 0.9321414840445982, 0.9329727641491211, 0.013153332813722038, 0.013153332813722038, 0.013153332813722038, 0.013153332813722038] \n",
      "\n",
      "Sensitivity: [0.9995913363302003, 0.9995913363302003, 0.9995913363302003, 0.9991826726604005, 0.9991826726604005, 0.9991826726604005, 0.9991826726604005, 0.9981610134859011, 0.9981610134859011, 0.998365345320801, 0.9975480179812015, 0.9973436861463016, 0.9963220269718022, 0.9938700449530037, 0.9908050674295055, 0.9869227625664079, 1.0, 1.0, 1.0, 1.0] \n",
      "\n",
      "F-score: [0.3568588831746727, 0.3322805230089998, 0.3805375131266774, 0.6060606060606061, 0.5396755325019315, 0.6561116328995036, 0.7635256460301351, 0.9265933232169954, 0.9386108175617254, 0.9460741601316681, 0.9583824106792305, 0.9612051988972036, 0.9629702774760541, 0.9626917367639783, 0.9605784469096671, 0.9591897527554365, 0.0259651375319325, 0.0259651375319325, 0.0259651375319325, 0.0259651375319325] \n",
      "\n",
      "MIN No_false: (375, 12) \n",
      "\n",
      "MAX Precision: (0.9334100940318557, 13) \n",
      "\n",
      "MAX Sensitivity: (1.0, 16) \n",
      "\n",
      "MAX F-score: (0.9629702774760541, 12) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## BASE LEARNERS CLASSIFICATION AND EVALUATION\n",
    "# Choose model\n",
    "## BASE LEARNERS CLASSIFICATION AND EVALUATION\n",
    "# Choose model\n",
    "print(\"BASE LEARNERS CLASSIFICATION PERFORMANCE:\")\n",
    "models = {\n",
    "#     'svm': ['linear', 'rbf'],\n",
    "    'lg': ['none', 'l2'],\n",
    "    'nn': ['relu', 'logistic'],\n",
    "}\n",
    "\n",
    "modelparam_range = [.001,.002,.005,.01,.02,.05,.1,.2,.5,1,5,10,20,50,100,200,500,1000,2000,5000] # C for svm, C for lg, alpha for NN\n",
    "for model, model_types in models.items():\n",
    "    for model_type in model_types:\n",
    "        precision = []\n",
    "        sensitivity = []\n",
    "        Fscore = []\n",
    "        nb_false = []\n",
    "        print(\"Model:\", model,\", Param_1:\",model_type, \", tuning range:\", modelparam_range)\n",
    "        for modelparam in modelparam_range:\n",
    "            md = train_model(model, modelparam, X_train, y_train, model_type)\n",
    "            final_result = classify(md, X_test)\n",
    "            final_eval = evaluation(y_test, final_result)\n",
    "            precision += [final_eval['precision']]\n",
    "            sensitivity += [final_eval['sensitivity']]\n",
    "            Fscore += [final_eval['F-score']]\n",
    "            nb_false  += [final_eval['no_false']]\n",
    "        print(\"No_false:\",nb_false,\"\\n\")\n",
    "        print(\"Precision:\",precision,\"\\n\")\n",
    "        print(\"Sensitivity:\",sensitivity,\"\\n\")\n",
    "        print(\"F-score:\", Fscore,\"\\n\")\n",
    "\n",
    "        print(\"MIN No_false:\",argmin(nb_false),\"\\n\")\n",
    "        print(\"MAX Precision:\",argmax(precision),\"\\n\")\n",
    "        print(\"MAX Sensitivity:\",argmax(sensitivity),\"\\n\")\n",
    "        print(\"MAX F-score:\", argmax(Fscore),\"\\n\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAGGING PERFORMANCE:\n",
      "\n",
      "svm per fold:\n",
      "Fold 0 {'no_false': 246, 'confusion_matrix': [4880, 232, 14, 366947], 'precision': 0.9546165884194053, 'sensitivity': 0.9971393543114018, 'no_links': 5112, 'F-score': 0.9754147511493104}\n",
      "Fold 1 {'no_false': 243, 'confusion_matrix': [4881, 230, 13, 366949], 'precision': 0.9549990217178634, 'sensitivity': 0.9973436861463016, 'no_links': 5111, 'F-score': 0.975712143928036}\n",
      "Fold 2 {'no_false': 284, 'confusion_matrix': [4881, 271, 13, 366908], 'precision': 0.9473990683229814, 'sensitivity': 0.9973436861463016, 'no_links': 5152, 'F-score': 0.9717300418076846}\n",
      "Fold 3 {'no_false': 246, 'confusion_matrix': [4881, 233, 13, 366946], 'precision': 0.9544387954634337, 'sensitivity': 0.9973436861463016, 'no_links': 5114, 'F-score': 0.9754196642685851}\n",
      "Fold 4 {'no_false': 257, 'confusion_matrix': [4881, 244, 13, 366935], 'precision': 0.952390243902439, 'sensitivity': 0.9973436861463016, 'no_links': 5125, 'F-score': 0.974348737398942}\n",
      "Fold 5 {'no_false': 253, 'confusion_matrix': [4881, 240, 13, 366939], 'precision': 0.9531341534856473, 'sensitivity': 0.9973436861463016, 'no_links': 5121, 'F-score': 0.9747378931602596}\n",
      "Fold 6 {'no_false': 291, 'confusion_matrix': [4881, 278, 13, 366901], 'precision': 0.9461135879046327, 'sensitivity': 0.9973436861463016, 'no_links': 5159, 'F-score': 0.9710534168904805}\n",
      "Fold 7 {'no_false': 290, 'confusion_matrix': [4881, 277, 13, 366902], 'precision': 0.946297014346646, 'sensitivity': 0.9973436861463016, 'no_links': 5158, 'F-score': 0.971150019896538}\n",
      "Fold 8 {'no_false': 280, 'confusion_matrix': [4881, 267, 13, 366912], 'precision': 0.9481351981351981, 'sensitivity': 0.9973436861463016, 'no_links': 5148, 'F-score': 0.9721171081457878}\n",
      "Fold 9 {'no_false': 262, 'confusion_matrix': [4881, 249, 13, 366930], 'precision': 0.9514619883040936, 'sensitivity': 0.9973436861463016, 'no_links': 5130, 'F-score': 0.9738627294493216}\n",
      "svm bagging: {'no_false': 259, 'confusion_matrix': [4881, 246, 13, 366933], 'precision': 0.952018724400234, 'sensitivity': 0.9973436861463016, 'no_links': 5127, 'F-score': 0.9741542760203572}\n",
      "\n",
      "nn per fold:\n",
      "Fold 0 {'no_false': 390, 'confusion_matrix': [4870, 366, 24, 366813], 'precision': 0.9300993124522536, 'sensitivity': 0.9950960359624029, 'no_links': 5236, 'F-score': 0.9615004935834156}\n",
      "Fold 1 {'no_false': 382, 'confusion_matrix': [4871, 359, 23, 366820], 'precision': 0.931357552581262, 'sensitivity': 0.9953003677973028, 'no_links': 5230, 'F-score': 0.9622678783089688}\n",
      "Fold 2 {'no_false': 393, 'confusion_matrix': [4873, 372, 21, 366807], 'precision': 0.9290753098188751, 'sensitivity': 0.9957090314671025, 'no_links': 5245, 'F-score': 0.9612387809448665}\n",
      "Fold 3 {'no_false': 391, 'confusion_matrix': [4872, 369, 22, 366810], 'precision': 0.929593589009731, 'sensitivity': 0.9955046996322027, 'no_links': 5241, 'F-score': 0.9614208189442526}\n",
      "Fold 4 {'no_false': 389, 'confusion_matrix': [4871, 366, 23, 366813], 'precision': 0.9301126599198014, 'sensitivity': 0.9953003677973028, 'no_links': 5237, 'F-score': 0.9616030006909485}\n",
      "Fold 5 {'no_false': 408, 'confusion_matrix': [4873, 387, 21, 366792], 'precision': 0.926425855513308, 'sensitivity': 0.9957090314671025, 'no_links': 5260, 'F-score': 0.9598187906243844}\n",
      "Fold 6 {'no_false': 403, 'confusion_matrix': [4873, 382, 21, 366797], 'precision': 0.9273073263558516, 'sensitivity': 0.9957090314671025, 'no_links': 5255, 'F-score': 0.9602916543501824}\n",
      "Fold 7 {'no_false': 409, 'confusion_matrix': [4871, 386, 23, 366793], 'precision': 0.9265740916872741, 'sensitivity': 0.9953003677973028, 'no_links': 5257, 'F-score': 0.9597084031129938}\n",
      "Fold 8 {'no_false': 407, 'confusion_matrix': [4872, 385, 22, 366794], 'precision': 0.9267643142476698, 'sensitivity': 0.9955046996322027, 'no_links': 5257, 'F-score': 0.9599054280366467}\n",
      "Fold 9 {'no_false': 408, 'confusion_matrix': [4873, 387, 21, 366792], 'precision': 0.926425855513308, 'sensitivity': 0.9957090314671025, 'no_links': 5260, 'F-score': 0.9598187906243844}\n",
      "nn bagging: {'no_false': 393, 'confusion_matrix': [4873, 372, 21, 366807], 'precision': 0.9290753098188751, 'sensitivity': 0.9957090314671025, 'no_links': 5245, 'F-score': 0.9612387809448665}\n",
      "\n",
      "lg per fold:\n",
      "Fold 0 {'no_false': 481, 'confusion_matrix': [4881, 468, 13, 366711], 'precision': 0.9125070106561974, 'sensitivity': 0.9973436861463016, 'no_links': 5349, 'F-score': 0.9530411012398712}\n",
      "Fold 1 {'no_false': 438, 'confusion_matrix': [4880, 424, 14, 366755], 'precision': 0.9200603318250377, 'sensitivity': 0.9971393543114018, 'no_links': 5304, 'F-score': 0.9570504020396157}\n",
      "Fold 2 {'no_false': 490, 'confusion_matrix': [4882, 478, 12, 366701], 'precision': 0.9108208955223881, 'sensitivity': 0.9975480179812015, 'no_links': 5360, 'F-score': 0.9522137702360055}\n",
      "Fold 3 {'no_false': 478, 'confusion_matrix': [4882, 466, 12, 366713], 'precision': 0.912864622288706, 'sensitivity': 0.9975480179812015, 'no_links': 5348, 'F-score': 0.9533294278461237}\n",
      "Fold 4 {'no_false': 470, 'confusion_matrix': [4882, 458, 12, 366721], 'precision': 0.9142322097378277, 'sensitivity': 0.9975480179812015, 'no_links': 5340, 'F-score': 0.9540746531170607}\n",
      "Fold 5 {'no_false': 524, 'confusion_matrix': [4882, 512, 12, 366667], 'precision': 0.9050797182054134, 'sensitivity': 0.9975480179812015, 'no_links': 5394, 'F-score': 0.9490668740279937}\n",
      "Fold 6 {'no_false': 490, 'confusion_matrix': [4882, 478, 12, 366701], 'precision': 0.9108208955223881, 'sensitivity': 0.9975480179812015, 'no_links': 5360, 'F-score': 0.9522137702360055}\n",
      "Fold 7 {'no_false': 485, 'confusion_matrix': [4882, 473, 12, 366706], 'precision': 0.911671335200747, 'sensitivity': 0.9975480179812015, 'no_links': 5355, 'F-score': 0.9526783100790321}\n",
      "Fold 8 {'no_false': 499, 'confusion_matrix': [4881, 486, 13, 366693], 'precision': 0.9094466182224706, 'sensitivity': 0.9973436861463016, 'no_links': 5367, 'F-score': 0.9513692622551408}\n",
      "Fold 9 {'no_false': 503, 'confusion_matrix': [4882, 491, 12, 366688], 'precision': 0.9086171598734413, 'sensitivity': 0.9975480179812015, 'no_links': 5373, 'F-score': 0.951008084153112}\n",
      "lg bagging: {'no_false': 490, 'confusion_matrix': [4882, 478, 12, 366701], 'precision': 0.9108208955223881, 'sensitivity': 0.9975480179812015, 'no_links': 5360, 'F-score': 0.9522137702360055}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## ENSEMBLE CLASSIFICATION AND EVALUATION\n",
    "\n",
    "print(\"BAGGING PERFORMANCE:\\n\")\n",
    "modeltypes = ['svm', 'nn', 'lg'] \n",
    "modeltypes_2 = ['linear', 'relu', 'l2']\n",
    "modelparams = [0.005, 100, 0.2]\n",
    "nFold = 10\n",
    "kf = KFold(n_splits=nFold)\n",
    "model_raw_score = [0]*3\n",
    "model_binary_score = [0]*3\n",
    "model_i = 0\n",
    "for model_i in range(3):\n",
    "    modeltype = modeltypes[model_i]\n",
    "    modeltype_2 = modeltypes_2[model_i]\n",
    "    modelparam = modelparams[model_i]\n",
    "    print(modeltype, \"per fold:\")\n",
    "    iFold = 0\n",
    "    result_fold = [0]*nFold\n",
    "    final_eval_fold = [0]*nFold\n",
    "    for train_index, valid_index in kf.split(X_train):\n",
    "        X_train_fold = X_train[train_index]\n",
    "        y_train_fold = y_train[train_index]\n",
    "        md =  train_model(modeltype, modelparam, X_train_fold, y_train_fold, modeltype_2)\n",
    "        result_fold[iFold] = classify(md, X_test)\n",
    "        final_eval_fold[iFold] = evaluation(y_test, result_fold[iFold])\n",
    "        print(\"Fold\", str(iFold), final_eval_fold[iFold])\n",
    "        iFold = iFold + 1\n",
    "    bagging_raw_score = np.average(result_fold, axis=0)\n",
    "    bagging_binary_score  = np.copy(bagging_raw_score)\n",
    "    bagging_binary_score[bagging_binary_score > 0.5] = 1\n",
    "    bagging_binary_score[bagging_binary_score <= 0.5] = 0\n",
    "    bagging_eval = evaluation(y_test, bagging_binary_score)\n",
    "    print(modeltype, \"bagging:\", bagging_eval)\n",
    "    print('')\n",
    "    model_raw_score[model_i] = bagging_raw_score\n",
    "    model_binary_score[model_i] = bagging_binary_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STACKING PERFORMANCE:\n",
      "\n",
      "{'no_false': 199, 'confusion_matrix': [4869, 174, 25, 367005], 'precision': 0.9654967281380131, 'sensitivity': 0.994891704127503, 'no_links': 5043, 'F-score': 0.9799738351615175}\n"
     ]
    }
   ],
   "source": [
    "thres = .99\n",
    "\n",
    "print(\"STACKING PERFORMANCE:\\n\")\n",
    "stack_raw_score = np.average(model_raw_score, axis=0)\n",
    "stack_binary_score = np.copy(stack_raw_score)\n",
    "stack_binary_score[stack_binary_score > thres] = 1\n",
    "stack_binary_score[stack_binary_score <= thres] = 0\n",
    "stacking_eval = evaluation(y_test, stack_binary_score)\n",
    "print(stacking_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
